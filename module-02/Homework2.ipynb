{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8e2ae0-da25-44e7-ae82-024173150a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57de60e5-b96c-499c-a7cf-0f30fc33b324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78f5cb1-709c-4b48-a9b9-1738b75415de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "qd_client = QdrantClient(\"http://localhost:6333\")\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "collection_name = \"zoomcamp-faq\"\n",
    "\n",
    "qd_client.delete_collection(collection_name=collection_name)\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")\n",
    "\n",
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "\n",
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4664a2-75f9-45d7-ab52-e12c03a624ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: -0.11726373551188797\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\", cache_dir=\".cache\")\n",
    "\n",
    "# Embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_embedding = list(model.embed([query]))[0]\n",
    "\n",
    "print(\"Min value:\", np.min(query_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f064b710-75d4-4cb3-b5ca-0485bcf4f4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9008528856818037\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "# Embed the document\n",
    "doc = \"Can I still join the course after the start date?\"\n",
    "doc_vector = list(model.embed([doc]))[0]\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = np.dot(query_embedding, doc_vector)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d2d4bb7-b33e-41c1-a8b3-4c152aa83717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document index: 1\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "# Embed document texts\n",
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "\n",
    "doc_texts = [doc[\"text\"] for doc in documents]\n",
    "doc_embeddings = list(model.embed(doc_texts))\n",
    "\n",
    "# Cosine similarity against the query\n",
    "similarities = [np.dot(query_embedding, doc_vec) for doc_vec in doc_embeddings]\n",
    "\n",
    "# Find the index of the most similar document\n",
    "most_similar_document_index = np.argmax(similarities)\n",
    "\n",
    "print(\"Most similar document index:\", most_similar_document_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082567b9-d6fd-4ef7-ab7e-6d88f24f5705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document index: 0\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "# Concatenate question + text\n",
    "full_texts = [doc[\"question\"] + \" \" + doc[\"text\"] for doc in documents]\n",
    "\n",
    "# Embed the full texts\n",
    "full_embeddings = list(model.embed(full_texts))\n",
    "\n",
    "# Compute cosine similarity using dot product\n",
    "V_full = np.array(full_embeddings)\n",
    "q = np.array(query_embedding)\n",
    "\n",
    "similarities_full = V_full.dot(q)\n",
    "\n",
    "# Find most similar\n",
    "best_index_full = np.argmax(similarities_full)\n",
    "\n",
    "print(\"Most similar document index:\", best_index_full)\n",
    "\n",
    "## Answer to reasoning question: Yes it is different than question 3. When we use both question and answer(i.e. text) in the embedding, it gave model more context. The question or the answer likely had wording similar to the query, increasing semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b090a1-f943-433c-b22b-ddc7044b3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest dimension available: 384\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Get the list of supported models\n",
    "models = TextEmbedding.list_supported_models()\n",
    "\n",
    "# Extract just the dimensionalities\n",
    "dims = [m[\"dim\"] for m in models]\n",
    "\n",
    "# Get the smallest one\n",
    "print(\"Smallest dimension available:\", min(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6ce2b4-2e46-4da1-91ef-0cd6210865dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Unknown arguments: ['query_vector']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m query_vector = \u001b[38;5;28mlist\u001b[39m(embedding_model.embed([query]))[\u001b[32m0\u001b[39m]\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Search the Qdrant collection\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m search_result = qd_client.query_points(\n\u001b[32m     51\u001b[39m     collection_name=collection_name,\n\u001b[32m     52\u001b[39m     query_vector=query_vector,\n\u001b[32m     53\u001b[39m     limit=\u001b[32m1\u001b[39m,\n\u001b[32m     54\u001b[39m     with_payload=\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# so you get back the question/text info\u001b[39;00m\n\u001b[32m     55\u001b[39m )\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Show top result\u001b[39;00m\n\u001b[32m     58\u001b[39m top_result = search_result[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/qdrant_client/qdrant_client.py:552\u001b[39m, in \u001b[36mQdrantClient.query_points\u001b[39m\u001b[34m(self, collection_name, query, using, prefetch, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, lookup_from, consistency, shard_key_selector, timeout, **kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery_points\u001b[39m(\n\u001b[32m    438\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    439\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    465\u001b[39m     **kwargs: Any,\n\u001b[32m    466\u001b[39m ) -> types.QueryResponse:\n\u001b[32m    467\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Universal endpoint to run any available operation, such as search, recommendation, discovery, context search.\u001b[39;00m\n\u001b[32m    468\u001b[39m \n\u001b[32m    469\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    549\u001b[39m \u001b[33;03m        QueryResponse structure containing list of found close points with similarity scores.\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) == \u001b[32m0\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    554\u001b[39m     \u001b[38;5;66;03m# If the query contains unprocessed documents, we need to embed them and\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;66;03m# replace the original query with the embedded vectors.\u001b[39;00m\n\u001b[32m    556\u001b[39m     query = \u001b[38;5;28mself\u001b[39m._resolve_query(query)\n",
      "\u001b[31mAssertionError\u001b[39m: Unknown arguments: ['query_vector']"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import PointStruct\n",
    "import requests\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = TextEmbedding(model_name=\"BAAI/bge-small-en\", cache_dir=\".cache\")\n",
    "EMBEDDING_DIMENSIONALITY = 384  # bge-small-en output size\n",
    "\n",
    "# Load ML Zoomcamp FAQ documents\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "documents_raw = requests.get(docs_url).json()\n",
    "\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    if course[\"course\"] != \"machine-learning-zoomcamp\":\n",
    "        continue\n",
    "    for doc in course[\"documents\"]:\n",
    "        doc[\"course\"] = course[\"course\"]\n",
    "        documents.append(doc)\n",
    "\n",
    "# Create in-memory Qdrant client\n",
    "qd_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create Qdrant collection\n",
    "collection_name = \"mlzoomcamp_faq\"\n",
    "qd_client.delete_collection(collection_name=collection_name)\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Insert document vectors into Qdrant\n",
    "points = []\n",
    "for idx, doc in enumerate(documents):\n",
    "    full_text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "    vector = list(embedding_model.embed([full_text]))[0]\n",
    "    points.append(PointStruct(id=idx, vector=vector, payload=doc))\n",
    "\n",
    "qd_client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# Embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_vector = list(embedding_model.embed([query]))[0]\n",
    "\n",
    "# Search the Qdrant collection\n",
    "search_result = qd_client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_vector,\n",
    "    limit=1,\n",
    "    with_payload=True  # so you get back the question/text info\n",
    ")\n",
    "\n",
    "# Show top result\n",
    "top_result = search_result[0]\n",
    "print(\"Top document score:\", top_result.score)\n",
    "print(\"Top document:\", top_result.payload[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d819f95-2422-4e84-8975-5694d829d534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b1456-7945-43a8-a8bb-005762b7d02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
